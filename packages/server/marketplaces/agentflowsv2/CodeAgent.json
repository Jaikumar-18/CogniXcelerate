{
    "nodes": [
      {
        "id": "startAgentflow_0",
        "type": "agentFlow",
        "position": {
          "x": -447.46290322374784,
          "y": 79.85204301079492
        },
        "data": {
          "id": "startAgentflow_0",
          "label": "Start",
          "version": 1.1,
          "name": "startAgentflow",
          "type": "Start",
          "color": "#7EE787",
          "hideInput": true,
          "baseClasses": [
            "Start"
          ],
          "category": "Agent Flows",
          "description": "Starting point of the agentflow",
          "inputParams": [
            {
              "label": "Input Type",
              "name": "startInputType",
              "type": "options",
              "options": [
                {
                  "label": "Chat Input",
                  "name": "chatInput",
                  "description": "Start the conversation with chat input"
                },
                {
                  "label": "Form Input",
                  "name": "formInput",
                  "description": "Start the workflow with form inputs"
                }
              ],
              "default": "chatInput",
              "id": "startAgentflow_0-input-startInputType-options",
              "display": true
            },
            {
              "label": "Form Title",
              "name": "formTitle",
              "type": "string",
              "placeholder": "Please Fill Out The Form",
              "show": {
                "startInputType": "formInput"
              },
              "id": "startAgentflow_0-input-formTitle-string",
              "display": false
            },
            {
              "label": "Form Description",
              "name": "formDescription",
              "type": "string",
              "placeholder": "Complete all fields below to continue",
              "show": {
                "startInputType": "formInput"
              },
              "id": "startAgentflow_0-input-formDescription-string",
              "display": false
            },
            {
              "label": "Form Input Types",
              "name": "formInputTypes",
              "description": "Specify the type of form input",
              "type": "array",
              "show": {
                "startInputType": "formInput"
              },
              "array": [
                {
                  "label": "Type",
                  "name": "type",
                  "type": "options",
                  "options": [
                    {
                      "label": "String",
                      "name": "string"
                    },
                    {
                      "label": "Number",
                      "name": "number"
                    },
                    {
                      "label": "Boolean",
                      "name": "boolean"
                    },
                    {
                      "label": "Options",
                      "name": "options"
                    }
                  ],
                  "default": "string"
                },
                {
                  "label": "Label",
                  "name": "label",
                  "type": "string",
                  "placeholder": "Label for the input"
                },
                {
                  "label": "Variable Name",
                  "name": "name",
                  "type": "string",
                  "placeholder": "Variable name for the input (must be camel case)",
                  "description": "Variable name must be camel case. For example: firstName, lastName, etc."
                },
                {
                  "label": "Add Options",
                  "name": "addOptions",
                  "type": "array",
                  "show": {
                    "formInputTypes[$index].type": "options"
                  },
                  "array": [
                    {
                      "label": "Option",
                      "name": "option",
                      "type": "string"
                    }
                  ]
                }
              ],
              "id": "startAgentflow_0-input-formInputTypes-array",
              "display": false
            },
            {
              "label": "Ephemeral Memory",
              "name": "startEphemeralMemory",
              "type": "boolean",
              "description": "Start fresh for every execution without past chat history",
              "optional": true,
              "id": "startAgentflow_0-input-startEphemeralMemory-boolean",
              "display": true
            },
            {
              "label": "Flow State",
              "name": "startState",
              "description": "Runtime state during the execution of the workflow",
              "type": "array",
              "optional": true,
              "array": [
                {
                  "label": "Key",
                  "name": "key",
                  "type": "string",
                  "placeholder": "Foo"
                },
                {
                  "label": "Value",
                  "name": "value",
                  "type": "string",
                  "placeholder": "Bar",
                  "optional": true
                }
              ],
              "id": "startAgentflow_0-input-startState-array",
              "display": true
            },
            {
              "label": "Persist State",
              "name": "startPersistState",
              "type": "boolean",
              "description": "Persist the state in the same session",
              "optional": true,
              "id": "startAgentflow_0-input-startPersistState-boolean",
              "display": true
            }
          ],
          "inputAnchors": [],
          "inputs": {
            "startInputType": "chatInput",
            "formTitle": "",
            "formDescription": "",
            "formInputTypes": "",
            "startEphemeralMemory": "",
            "startState": [
              {
                "key": "next",
                "value": ""
              },
              {
                "key": "instructions",
                "value": ""
              },
              {
                "key": "input",
                "value": ""
              }
            ],
            "startPersistState": ""
          },
          "outputAnchors": [
            {
              "id": "startAgentflow_0-output-startAgentflow",
              "label": "Start",
              "name": "startAgentflow"
            }
          ],
          "outputs": {},
          "selected": false
        },
        "width": 103,
        "height": 66,
        "selected": false,
        "positionAbsolute": {
          "x": -447.46290322374784,
          "y": 79.85204301079492
        },
        "dragging": false
      },
      {
        "id": "llmAgentflow_0",
        "position": {
          "x": -307.61239894375564,
          "y": 78.0387370944749
        },
        "data": {
          "id": "llmAgentflow_0",
          "label": "Supervisor",
          "version": 1,
          "name": "llmAgentflow",
          "type": "LLM",
          "color": "#64B5F6",
          "baseClasses": [
            "LLM"
          ],
          "category": "Agent Flows",
          "description": "Large language models to analyze user-provided inputs and generate responses",
          "inputParams": [
            {
              "label": "Model",
              "name": "llmModel",
              "type": "asyncOptions",
              "loadMethod": "listModels",
              "loadConfig": true,
              "id": "llmAgentflow_0-input-llmModel-asyncOptions",
              "display": true
            },
            {
              "label": "Messages",
              "name": "llmMessages",
              "type": "array",
              "optional": true,
              "acceptVariable": true,
              "array": [
                {
                  "label": "Role",
                  "name": "role",
                  "type": "options",
                  "options": [
                    {
                      "label": "System",
                      "name": "system"
                    },
                    {
                      "label": "Assistant",
                      "name": "assistant"
                    },
                    {
                      "label": "Developer",
                      "name": "developer"
                    },
                    {
                      "label": "User",
                      "name": "user"
                    }
                  ]
                },
                {
                  "label": "Content",
                  "name": "content",
                  "type": "string",
                  "acceptVariable": true,
                  "generateInstruction": true,
                  "rows": 4
                }
              ],
              "id": "llmAgentflow_0-input-llmMessages-array",
              "display": true
            },
            {
              "label": "Enable Memory",
              "name": "llmEnableMemory",
              "type": "boolean",
              "description": "Enable memory for the conversation thread",
              "default": true,
              "optional": true,
              "id": "llmAgentflow_0-input-llmEnableMemory-boolean",
              "display": true
            },
            {
              "label": "Memory Type",
              "name": "llmMemoryType",
              "type": "options",
              "options": [
                {
                  "label": "All Messages",
                  "name": "allMessages",
                  "description": "Retrieve all messages from the conversation"
                },
                {
                  "label": "Window Size",
                  "name": "windowSize",
                  "description": "Uses a fixed window size to surface the last N messages"
                },
                {
                  "label": "Conversation Summary",
                  "name": "conversationSummary",
                  "description": "Summarizes the whole conversation"
                },
                {
                  "label": "Conversation Summary Buffer",
                  "name": "conversationSummaryBuffer",
                  "description": "Summarize conversations once token limit is reached. Default to 2000"
                }
              ],
              "optional": true,
              "default": "allMessages",
              "show": {
                "llmEnableMemory": true
              },
              "id": "llmAgentflow_0-input-llmMemoryType-options",
              "display": true
            },
            {
              "label": "Window Size",
              "name": "llmMemoryWindowSize",
              "type": "number",
              "default": "20",
              "description": "Uses a fixed window size to surface the last N messages",
              "show": {
                "llmMemoryType": "windowSize"
              },
              "id": "llmAgentflow_0-input-llmMemoryWindowSize-number",
              "display": false
            },
            {
              "label": "Max Token Limit",
              "name": "llmMemoryMaxTokenLimit",
              "type": "number",
              "default": "2000",
              "description": "Summarize conversations once token limit is reached. Default to 2000",
              "show": {
                "llmMemoryType": "conversationSummaryBuffer"
              },
              "id": "llmAgentflow_0-input-llmMemoryMaxTokenLimit-number",
              "display": false
            },
            {
              "label": "Input Message",
              "name": "llmUserMessage",
              "type": "string",
              "description": "Add an input message as user message at the end of the conversation",
              "rows": 4,
              "optional": true,
              "acceptVariable": true,
              "show": {
                "llmEnableMemory": true
              },
              "id": "llmAgentflow_0-input-llmUserMessage-string",
              "display": true
            },
            {
              "label": "Return Response As",
              "name": "llmReturnResponseAs",
              "type": "options",
              "options": [
                {
                  "label": "User Message",
                  "name": "userMessage"
                },
                {
                  "label": "Assistant Message",
                  "name": "assistantMessage"
                }
              ],
              "default": "userMessage",
              "id": "llmAgentflow_0-input-llmReturnResponseAs-options",
              "display": true
            },
            {
              "label": "JSON Structured Output",
              "name": "llmStructuredOutput",
              "description": "Instruct the LLM to give output in a JSON structured schema",
              "type": "array",
              "optional": true,
              "acceptVariable": true,
              "array": [
                {
                  "label": "Key",
                  "name": "key",
                  "type": "string"
                },
                {
                  "label": "Type",
                  "name": "type",
                  "type": "options",
                  "options": [
                    {
                      "label": "String",
                      "name": "string"
                    },
                    {
                      "label": "String Array",
                      "name": "stringArray"
                    },
                    {
                      "label": "Number",
                      "name": "number"
                    },
                    {
                      "label": "Boolean",
                      "name": "boolean"
                    },
                    {
                      "label": "Enum",
                      "name": "enum"
                    },
                    {
                      "label": "JSON Array",
                      "name": "jsonArray"
                    }
                  ]
                },
                {
                  "label": "Enum Values",
                  "name": "enumValues",
                  "type": "string",
                  "placeholder": "value1, value2, value3",
                  "description": "Enum values. Separated by comma",
                  "optional": true,
                  "show": {
                    "llmStructuredOutput[$index].type": "enum"
                  }
                },
                {
                  "label": "JSON Schema",
                  "name": "jsonSchema",
                  "type": "code",
                  "placeholder": "{\n    \"answer\": {\n        \"type\": \"string\",\n        \"description\": \"Value of the answer\"\n    },\n    \"reason\": {\n        \"type\": \"string\",\n        \"description\": \"Reason for the answer\"\n    },\n    \"optional\": {\n        \"type\": \"boolean\"\n    },\n    \"count\": {\n        \"type\": \"number\"\n    },\n    \"children\": {\n        \"type\": \"array\",\n        \"items\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"value\": {\n                    \"type\": \"string\",\n                    \"description\": \"Value of the children's answer\"\n                }\n            }\n        }\n    }\n}",
                  "description": "JSON schema for the structured output",
                  "optional": true,
                  "hideCodeExecute": true,
                  "show": {
                    "llmStructuredOutput[$index].type": "jsonArray"
                  }
                },
                {
                  "label": "Description",
                  "name": "description",
                  "type": "string",
                  "placeholder": "Description of the key"
                }
              ],
              "id": "llmAgentflow_0-input-llmStructuredOutput-array",
              "display": true
            },
            {
              "label": "Update Flow State",
              "name": "llmUpdateState",
              "description": "Update runtime state during the execution of the workflow",
              "type": "array",
              "optional": true,
              "acceptVariable": true,
              "array": [
                {
                  "label": "Key",
                  "name": "key",
                  "type": "asyncOptions",
                  "loadMethod": "listRuntimeStateKeys",
                  "freeSolo": true
                },
                {
                  "label": "Value",
                  "name": "value",
                  "type": "string",
                  "acceptVariable": true,
                  "acceptNodeOutputAsVariable": true
                }
              ],
              "id": "llmAgentflow_0-input-llmUpdateState-array",
              "display": true
            }
          ],
          "inputAnchors": [],
          "inputs": {
            "llmModel": "chatGoogleGenerativeAI",
            "llmMessages": [
              {
                "role": "system",
                "content": "<p>You are a supervisor tasked with managing a conversation between the following workers:</p><p>- Software Engineer  </p><p>- Code Reviewer</p><p>Given the following user request, respond with the worker to act next.</p><p>Each worker will perform a task and respond with their results and status.</p><p>When finished, respond with FINISH.</p><p>Select strategically to minimize the number of steps taken.</p>"
              }
            ],
            "llmEnableMemory": true,
            "llmMemoryType": "allMessages",
            "llmUserMessage": "",
            "llmReturnResponseAs": "userMessage",
            "llmStructuredOutput": [
              {
                "key": "next",
                "type": "enum",
                "enumValues": "SOFTWARE, REVIEWER, FINISH",
                "jsonSchema": "",
                "description": "Next worker to work"
              },
              {
                "key": "instructions",
                "type": "string",
                "enumValues": "",
                "jsonSchema": "",
                "description": "The specific instructions of the sub-task the next worker should accomplish"
              }
            ],
            "llmUpdateState": [
              {
                "key": "next",
                "value": "<p><span class=\"variable\" data-type=\"mention\" data-id=\"output.next\" data-label=\"output.next\">{{ output.next }}</span></p>"
              },
              {
                "key": "instructions",
                "value": "<p><span class=\"variable\" data-type=\"mention\" data-id=\"output.instructions\" data-label=\"output.instructions\">{{ output.instructions }}</span> </p>"
              }
            ],
            "llmModelConfig": {
              "credential": "",
              "modelName": "gemini-2.5-flash-preview-05-20",
              "customModelName": "",
              "temperature": 0.9,
              "streaming": true,
              "maxOutputTokens": "",
              "topP": "",
              "topK": "",
              "safetySettings": "",
              "baseUrl": "",
              "allowImageUploads": "",
              "llmModel": "chatGoogleGenerativeAI"
            }
          },
          "outputAnchors": [
            {
              "id": "llmAgentflow_0-output-llmAgentflow",
              "label": "LLM",
              "name": "llmAgentflow"
            }
          ],
          "outputs": {},
          "selected": false
        },
        "type": "agentFlow",
        "width": 283,
        "height": 72,
        "selected": false,
        "positionAbsolute": {
          "x": -307.61239894375564,
          "y": 78.0387370944749
        },
        "dragging": false
      },
      {
        "id": "conditionAgentflow_0",
        "position": {
          "x": 11.79191436256042,
          "y": 67.56645067258927
        },
        "data": {
          "id": "conditionAgentflow_0",
          "label": "Check Next Worker",
          "version": 1,
          "name": "conditionAgentflow",
          "type": "Condition",
          "color": "#FFB938",
          "baseClasses": [
            "Condition"
          ],
          "category": "Agent Flows",
          "description": "Split flows based on If Else conditions",
          "inputParams": [
            {
              "label": "Conditions",
              "name": "conditions",
              "type": "array",
              "description": "Values to compare",
              "acceptVariable": true,
              "default": [
                {
                  "type": "string",
                  "value1": "<p><span class=\"variable\" data-type=\"mention\" data-id=\"$flow.state.next\" data-label=\"$flow.state.next\">{{ $flow.state.next }}</span> </p>",
                  "operation": "equal",
                  "value2": "<p>SOFTWARE</p>"
                }
              ],
              "array": [
                {
                  "label": "Type",
                  "name": "type",
                  "type": "options",
                  "options": [
                    {
                      "label": "String",
                      "name": "string"
                    },
                    {
                      "label": "Number",
                      "name": "number"
                    },
                    {
                      "label": "Boolean",
                      "name": "boolean"
                    }
                  ],
                  "default": "string"
                },
                {
                  "label": "Value 1",
                  "name": "value1",
                  "type": "string",
                  "default": "",
                  "description": "First value to be compared with",
                  "acceptVariable": true,
                  "show": {
                    "conditions[$index].type": "string"
                  }
                },
                {
                  "label": "Operation",
                  "name": "operation",
                  "type": "options",
                  "options": [
                    {
                      "label": "Contains",
                      "name": "contains"
                    },
                    {
                      "label": "Ends With",
                      "name": "endsWith"
                    },
                    {
                      "label": "Equal",
                      "name": "equal"
                    },
                    {
                      "label": "Not Contains",
                      "name": "notContains"
                    },
                    {
                      "label": "Not Equal",
                      "name": "notEqual"
                    },
                    {
                      "label": "Regex",
                      "name": "regex"
                    },
                    {
                      "label": "Starts With",
                      "name": "startsWith"
                    },
                    {
                      "label": "Is Empty",
                      "name": "isEmpty"
                    },
                    {
                      "label": "Not Empty",
                      "name": "notEmpty"
                    }
                  ],
                  "default": "equal",
                  "description": "Type of operation",
                  "show": {
                    "conditions[$index].type": "string"
                  }
                },
                {
                  "label": "Value 2",
                  "name": "value2",
                  "type": "string",
                  "default": "",
                  "description": "Second value to be compared with",
                  "acceptVariable": true,
                  "show": {
                    "conditions[$index].type": "string"
                  },
                  "hide": {
                    "conditions[$index].operation": [
                      "isEmpty",
                      "notEmpty"
                    ]
                  }
                },
                {
                  "label": "Value 1",
                  "name": "value1",
                  "type": "number",
                  "default": "",
                  "description": "First value to be compared with",
                  "acceptVariable": true,
                  "show": {
                    "conditions[$index].type": "number"
                  }
                },
                {
                  "label": "Operation",
                  "name": "operation",
                  "type": "options",
                  "options": [
                    {
                      "label": "Smaller",
                      "name": "smaller"
                    },
                    {
                      "label": "Smaller Equal",
                      "name": "smallerEqual"
                    },
                    {
                      "label": "Equal",
                      "name": "equal"
                    },
                    {
                      "label": "Not Equal",
                      "name": "notEqual"
                    },
                    {
                      "label": "Larger",
                      "name": "larger"
                    },
                    {
                      "label": "Larger Equal",
                      "name": "largerEqual"
                    },
                    {
                      "label": "Is Empty",
                      "name": "isEmpty"
                    },
                    {
                      "label": "Not Empty",
                      "name": "notEmpty"
                    }
                  ],
                  "default": "equal",
                  "description": "Type of operation",
                  "show": {
                    "conditions[$index].type": "number"
                  }
                },
                {
                  "label": "Value 2",
                  "name": "value2",
                  "type": "number",
                  "default": 0,
                  "description": "Second value to be compared with",
                  "acceptVariable": true,
                  "show": {
                    "conditions[$index].type": "number"
                  }
                },
                {
                  "label": "Value 1",
                  "name": "value1",
                  "type": "boolean",
                  "default": false,
                  "description": "First value to be compared with",
                  "show": {
                    "conditions[$index].type": "boolean"
                  }
                },
                {
                  "label": "Operation",
                  "name": "operation",
                  "type": "options",
                  "options": [
                    {
                      "label": "Equal",
                      "name": "equal"
                    },
                    {
                      "label": "Not Equal",
                      "name": "notEqual"
                    }
                  ],
                  "default": "equal",
                  "description": "Type of operation",
                  "show": {
                    "conditions[$index].type": "boolean"
                  }
                },
                {
                  "label": "Value 2",
                  "name": "value2",
                  "type": "boolean",
                  "default": false,
                  "description": "Second value to be compared with",
                  "show": {
                    "conditions[$index].type": "boolean"
                  }
                }
              ],
              "id": "conditionAgentflow_0-input-conditions-array",
              "display": true
            }
          ],
          "inputAnchors": [],
          "inputs": {
            "conditions": [
              {
                "type": "string",
                "value1": "<p><span class=\"variable\" data-type=\"mention\" data-id=\"$flow.state.next\" data-label=\"$flow.state.next\">{{ $flow.state.next }}</span> </p>",
                "operation": "equal",
                "value2": "<p>SOFTWARE</p>"
              },
              {
                "type": "string",
                "value1": "<p><span class=\"variable\" data-type=\"mention\" data-id=\"$flow.state.next\" data-label=\"$flow.state.next\">{{ $flow.state.next }}</span> </p>",
                "operation": "equal",
                "value2": "<p>REVIEWER</p>"
              }
            ]
          },
          "outputAnchors": [
            {
              "id": "conditionAgentflow_0-output-0",
              "label": 0,
              "name": 0,
              "description": "Condition 0"
            },
            {
              "id": "conditionAgentflow_0-output-1",
              "label": 1,
              "name": 1,
              "description": "Condition 1"
            },
            {
              "id": "conditionAgentflow_0-output-2",
              "label": 2,
              "name": 2,
              "description": "Else"
            }
          ],
          "outputs": {
            "conditionAgentflow": ""
          },
          "selected": false
        },
        "type": "agentFlow",
        "width": 198,
        "height": 100,
        "selected": false,
        "dragging": false,
        "positionAbsolute": {
          "x": 11.79191436256042,
          "y": 67.56645067258927
        }
      },
      {
        "id": "llmAgentflow_1",
        "position": {
          "x": 266.7880499980127,
          "y": -49.22382305367758
        },
        "data": {
          "id": "llmAgentflow_1",
          "label": "Software Engineer",
          "version": 1,
          "name": "llmAgentflow",
          "type": "LLM",
          "color": "#64B5F6",
          "baseClasses": [
            "LLM"
          ],
          "category": "Agent Flows",
          "description": "Large language models to analyze user-provided inputs and generate responses",
          "inputParams": [
            {
              "label": "Model",
              "name": "llmModel",
              "type": "asyncOptions",
              "loadMethod": "listModels",
              "loadConfig": true,
              "id": "llmAgentflow_1-input-llmModel-asyncOptions",
              "display": true
            },
            {
              "label": "Messages",
              "name": "llmMessages",
              "type": "array",
              "optional": true,
              "acceptVariable": true,
              "array": [
                {
                  "label": "Role",
                  "name": "role",
                  "type": "options",
                  "options": [
                    {
                      "label": "System",
                      "name": "system"
                    },
                    {
                      "label": "Assistant",
                      "name": "assistant"
                    },
                    {
                      "label": "Developer",
                      "name": "developer"
                    },
                    {
                      "label": "User",
                      "name": "user"
                    }
                  ]
                },
                {
                  "label": "Content",
                  "name": "content",
                  "type": "string",
                  "acceptVariable": true,
                  "generateInstruction": true,
                  "rows": 4
                }
              ],
              "id": "llmAgentflow_1-input-llmMessages-array",
              "display": true
            },
            {
              "label": "Enable Memory",
              "name": "llmEnableMemory",
              "type": "boolean",
              "description": "Enable memory for the conversation thread",
              "default": true,
              "optional": true,
              "id": "llmAgentflow_1-input-llmEnableMemory-boolean",
              "display": true
            },
            {
              "label": "Memory Type",
              "name": "llmMemoryType",
              "type": "options",
              "options": [
                {
                  "label": "All Messages",
                  "name": "allMessages",
                  "description": "Retrieve all messages from the conversation"
                },
                {
                  "label": "Window Size",
                  "name": "windowSize",
                  "description": "Uses a fixed window size to surface the last N messages"
                },
                {
                  "label": "Conversation Summary",
                  "name": "conversationSummary",
                  "description": "Summarizes the whole conversation"
                },
                {
                  "label": "Conversation Summary Buffer",
                  "name": "conversationSummaryBuffer",
                  "description": "Summarize conversations once token limit is reached. Default to 2000"
                }
              ],
              "optional": true,
              "default": "allMessages",
              "show": {
                "llmEnableMemory": true
              },
              "id": "llmAgentflow_1-input-llmMemoryType-options",
              "display": true
            },
            {
              "label": "Window Size",
              "name": "llmMemoryWindowSize",
              "type": "number",
              "default": "20",
              "description": "Uses a fixed window size to surface the last N messages",
              "show": {
                "llmMemoryType": "windowSize"
              },
              "id": "llmAgentflow_1-input-llmMemoryWindowSize-number",
              "display": false
            },
            {
              "label": "Max Token Limit",
              "name": "llmMemoryMaxTokenLimit",
              "type": "number",
              "default": "2000",
              "description": "Summarize conversations once token limit is reached. Default to 2000",
              "show": {
                "llmMemoryType": "conversationSummaryBuffer"
              },
              "id": "llmAgentflow_1-input-llmMemoryMaxTokenLimit-number",
              "display": false
            },
            {
              "label": "Input Message",
              "name": "llmUserMessage",
              "type": "string",
              "description": "Add an input message as user message at the end of the conversation",
              "rows": 4,
              "optional": true,
              "acceptVariable": true,
              "show": {
                "llmEnableMemory": true
              },
              "id": "llmAgentflow_1-input-llmUserMessage-string",
              "display": true
            },
            {
              "label": "Return Response As",
              "name": "llmReturnResponseAs",
              "type": "options",
              "options": [
                {
                  "label": "User Message",
                  "name": "userMessage"
                },
                {
                  "label": "Assistant Message",
                  "name": "assistantMessage"
                }
              ],
              "default": "userMessage",
              "id": "llmAgentflow_1-input-llmReturnResponseAs-options",
              "display": true
            },
            {
              "label": "JSON Structured Output",
              "name": "llmStructuredOutput",
              "description": "Instruct the LLM to give output in a JSON structured schema",
              "type": "array",
              "optional": true,
              "acceptVariable": true,
              "array": [
                {
                  "label": "Key",
                  "name": "key",
                  "type": "string"
                },
                {
                  "label": "Type",
                  "name": "type",
                  "type": "options",
                  "options": [
                    {
                      "label": "String",
                      "name": "string"
                    },
                    {
                      "label": "String Array",
                      "name": "stringArray"
                    },
                    {
                      "label": "Number",
                      "name": "number"
                    },
                    {
                      "label": "Boolean",
                      "name": "boolean"
                    },
                    {
                      "label": "Enum",
                      "name": "enum"
                    },
                    {
                      "label": "JSON Array",
                      "name": "jsonArray"
                    }
                  ]
                },
                {
                  "label": "Enum Values",
                  "name": "enumValues",
                  "type": "string",
                  "placeholder": "value1, value2, value3",
                  "description": "Enum values. Separated by comma",
                  "optional": true,
                  "show": {
                    "llmStructuredOutput[$index].type": "enum"
                  }
                },
                {
                  "label": "JSON Schema",
                  "name": "jsonSchema",
                  "type": "code",
                  "placeholder": "{\n    \"answer\": {\n        \"type\": \"string\",\n        \"description\": \"Value of the answer\"\n    },\n    \"reason\": {\n        \"type\": \"string\",\n        \"description\": \"Reason for the answer\"\n    },\n    \"optional\": {\n        \"type\": \"boolean\"\n    },\n    \"count\": {\n        \"type\": \"number\"\n    },\n    \"children\": {\n        \"type\": \"array\",\n        \"items\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"value\": {\n                    \"type\": \"string\",\n                    \"description\": \"Value of the children's answer\"\n                }\n            }\n        }\n    }\n}",
                  "description": "JSON schema for the structured output",
                  "optional": true,
                  "hideCodeExecute": true,
                  "show": {
                    "llmStructuredOutput[$index].type": "jsonArray"
                  }
                },
                {
                  "label": "Description",
                  "name": "description",
                  "type": "string",
                  "placeholder": "Description of the key"
                }
              ],
              "id": "llmAgentflow_1-input-llmStructuredOutput-array",
              "display": true
            },
            {
              "label": "Update Flow State",
              "name": "llmUpdateState",
              "description": "Update runtime state during the execution of the workflow",
              "type": "array",
              "optional": true,
              "acceptVariable": true,
              "array": [
                {
                  "label": "Key",
                  "name": "key",
                  "type": "asyncOptions",
                  "loadMethod": "listRuntimeStateKeys",
                  "freeSolo": true
                },
                {
                  "label": "Value",
                  "name": "value",
                  "type": "string",
                  "acceptVariable": true,
                  "acceptNodeOutputAsVariable": true
                }
              ],
              "id": "llmAgentflow_1-input-llmUpdateState-array",
              "display": true
            }
          ],
          "inputAnchors": [],
          "inputs": {
            "llmModel": "chatGoogleGenerativeAI",
            "llmMessages": [
              {
                "role": "system",
                "content": "<p>As a Senior Software Engineer, you are a pivotal part of our innovative development team. Your expertise and leadership drive the creation of robust, scalable software solutions that meet the needs of our diverse clientele.</p><p>Your goal is to lead the development of high-quality software solutions.</p><p>Design and implement new features for the given task, ensuring it integrates seamlessly with existing systems and meets performance requirements. Use your understanding of React, TailwindCSS, NodeJS to build this feature. Make sure to adhere to coding standards and follow best practices.</p><p>The output should be a fully functional, well-documented feature that enhances our product's capabilities. Include detailed comments in the code.</p>"
              }
            ],
            "llmEnableMemory": true,
            "llmMemoryType": "allMessages",
            "llmUserMessage": "<p>Supervisor Instruction:</p><p><span class=\"variable\" data-type=\"mention\" data-id=\"$flow.state.instructions\" data-label=\"$flow.state.instructions\">{{ $flow.state.instructions }}</span> </p>",
            "llmReturnResponseAs": "userMessage",
            "llmStructuredOutput": "",
            "llmUpdateState": "",
            "llmModelConfig": {
              "credential": "",
              "modelName": "gemini-2.5-flash-preview-05-20",
              "customModelName": "",
              "temperature": 0.9,
              "streaming": true,
              "maxOutputTokens": "",
              "topP": "",
              "topK": "",
              "safetySettings": "",
              "baseUrl": "",
              "allowImageUploads": "",
              "llmModel": "chatGoogleGenerativeAI"
            }
          },
          "outputAnchors": [
            {
              "id": "llmAgentflow_1-output-llmAgentflow",
              "label": "LLM",
              "name": "llmAgentflow"
            }
          ],
          "outputs": {},
          "selected": false
        },
        "type": "agentFlow",
        "width": 283,
        "height": 72,
        "selected": false,
        "positionAbsolute": {
          "x": 266.7880499980127,
          "y": -49.22382305367758
        },
        "dragging": false
      },
      {
        "id": "loopAgentflow_0",
        "position": {
          "x": 602.5844477474029,
          "y": -46.34245805256079
        },
        "data": {
          "id": "loopAgentflow_0",
          "label": "Loop to Supervisor",
          "version": 1,
          "name": "loopAgentflow",
          "type": "Loop",
          "color": "#FFA07A",
          "hideOutput": true,
          "baseClasses": [
            "Loop"
          ],
          "category": "Agent Flows",
          "description": "Loop back to a previous node",
          "inputParams": [
            {
              "label": "Loop Back To",
              "name": "loopBackToNode",
              "type": "asyncOptions",
              "loadMethod": "listPreviousNodes",
              "freeSolo": true,
              "id": "loopAgentflow_0-input-loopBackToNode-asyncOptions",
              "display": true
            },
            {
              "label": "Max Loop Count",
              "name": "maxLoopCount",
              "type": "number",
              "default": 5,
              "id": "loopAgentflow_0-input-maxLoopCount-number",
              "display": true
            }
          ],
          "inputAnchors": [],
          "inputs": {
            "loopBackToNode": "llmAgentflow_0-Supervisor",
            "maxLoopCount": "3"
          },
          "outputAnchors": [],
          "outputs": {},
          "selected": false
        },
        "type": "agentFlow",
        "width": 195,
        "height": 66,
        "selected": false,
        "dragging": false,
        "positionAbsolute": {
          "x": 602.5844477474029,
          "y": -46.34245805256079
        }
      },
      {
        "id": "llmAgentflow_2",
        "position": {
          "x": 275.82767406990337,
          "y": 82.77476864566805
        },
        "data": {
          "id": "llmAgentflow_2",
          "label": "Test Engineer",
          "version": 1,
          "name": "llmAgentflow",
          "type": "LLM",
          "color": "#64B5F6",
          "baseClasses": [
            "LLM"
          ],
          "category": "Agent Flows",
          "description": "Large language models to analyze user-provided inputs and generate responses",
          "inputParams": [
            {
              "label": "Model",
              "name": "llmModel",
              "type": "asyncOptions",
              "loadMethod": "listModels",
              "loadConfig": true,
              "id": "llmAgentflow_2-input-llmModel-asyncOptions",
              "display": true
            },
            {
              "label": "Messages",
              "name": "llmMessages",
              "type": "array",
              "optional": true,
              "acceptVariable": true,
              "array": [
                {
                  "label": "Role",
                  "name": "role",
                  "type": "options",
                  "options": [
                    {
                      "label": "System",
                      "name": "system"
                    },
                    {
                      "label": "Assistant",
                      "name": "assistant"
                    },
                    {
                      "label": "Developer",
                      "name": "developer"
                    },
                    {
                      "label": "User",
                      "name": "user"
                    }
                  ]
                },
                {
                  "label": "Content",
                  "name": "content",
                  "type": "string",
                  "acceptVariable": true,
                  "generateInstruction": true,
                  "rows": 4
                }
              ],
              "id": "llmAgentflow_2-input-llmMessages-array",
              "display": true
            },
            {
              "label": "Enable Memory",
              "name": "llmEnableMemory",
              "type": "boolean",
              "description": "Enable memory for the conversation thread",
              "default": true,
              "optional": true,
              "id": "llmAgentflow_2-input-llmEnableMemory-boolean",
              "display": true
            },
            {
              "label": "Memory Type",
              "name": "llmMemoryType",
              "type": "options",
              "options": [
                {
                  "label": "All Messages",
                  "name": "allMessages",
                  "description": "Retrieve all messages from the conversation"
                },
                {
                  "label": "Window Size",
                  "name": "windowSize",
                  "description": "Uses a fixed window size to surface the last N messages"
                },
                {
                  "label": "Conversation Summary",
                  "name": "conversationSummary",
                  "description": "Summarizes the whole conversation"
                },
                {
                  "label": "Conversation Summary Buffer",
                  "name": "conversationSummaryBuffer",
                  "description": "Summarize conversations once token limit is reached. Default to 2000"
                }
              ],
              "optional": true,
              "default": "allMessages",
              "show": {
                "llmEnableMemory": true
              },
              "id": "llmAgentflow_2-input-llmMemoryType-options",
              "display": true
            },
            {
              "label": "Window Size",
              "name": "llmMemoryWindowSize",
              "type": "number",
              "default": "20",
              "description": "Uses a fixed window size to surface the last N messages",
              "show": {
                "llmMemoryType": "windowSize"
              },
              "id": "llmAgentflow_2-input-llmMemoryWindowSize-number",
              "display": false
            },
            {
              "label": "Max Token Limit",
              "name": "llmMemoryMaxTokenLimit",
              "type": "number",
              "default": "2000",
              "description": "Summarize conversations once token limit is reached. Default to 2000",
              "show": {
                "llmMemoryType": "conversationSummaryBuffer"
              },
              "id": "llmAgentflow_2-input-llmMemoryMaxTokenLimit-number",
              "display": false
            },
            {
              "label": "Input Message",
              "name": "llmUserMessage",
              "type": "string",
              "description": "Add an input message as user message at the end of the conversation",
              "rows": 4,
              "optional": true,
              "acceptVariable": true,
              "show": {
                "llmEnableMemory": true
              },
              "id": "llmAgentflow_2-input-llmUserMessage-string",
              "display": true
            },
            {
              "label": "Return Response As",
              "name": "llmReturnResponseAs",
              "type": "options",
              "options": [
                {
                  "label": "User Message",
                  "name": "userMessage"
                },
                {
                  "label": "Assistant Message",
                  "name": "assistantMessage"
                }
              ],
              "default": "userMessage",
              "id": "llmAgentflow_2-input-llmReturnResponseAs-options",
              "display": true
            },
            {
              "label": "JSON Structured Output",
              "name": "llmStructuredOutput",
              "description": "Instruct the LLM to give output in a JSON structured schema",
              "type": "array",
              "optional": true,
              "acceptVariable": true,
              "array": [
                {
                  "label": "Key",
                  "name": "key",
                  "type": "string"
                },
                {
                  "label": "Type",
                  "name": "type",
                  "type": "options",
                  "options": [
                    {
                      "label": "String",
                      "name": "string"
                    },
                    {
                      "label": "String Array",
                      "name": "stringArray"
                    },
                    {
                      "label": "Number",
                      "name": "number"
                    },
                    {
                      "label": "Boolean",
                      "name": "boolean"
                    },
                    {
                      "label": "Enum",
                      "name": "enum"
                    },
                    {
                      "label": "JSON Array",
                      "name": "jsonArray"
                    }
                  ]
                },
                {
                  "label": "Enum Values",
                  "name": "enumValues",
                  "type": "string",
                  "placeholder": "value1, value2, value3",
                  "description": "Enum values. Separated by comma",
                  "optional": true,
                  "show": {
                    "llmStructuredOutput[$index].type": "enum"
                  }
                },
                {
                  "label": "JSON Schema",
                  "name": "jsonSchema",
                  "type": "code",
                  "placeholder": "{\n    \"answer\": {\n        \"type\": \"string\",\n        \"description\": \"Value of the answer\"\n    },\n    \"reason\": {\n        \"type\": \"string\",\n        \"description\": \"Reason for the answer\"\n    },\n    \"optional\": {\n        \"type\": \"boolean\"\n    },\n    \"count\": {\n        \"type\": \"number\"\n    },\n    \"children\": {\n        \"type\": \"array\",\n        \"items\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"value\": {\n                    \"type\": \"string\",\n                    \"description\": \"Value of the children's answer\"\n                }\n            }\n        }\n    }\n}",
                  "description": "JSON schema for the structured output",
                  "optional": true,
                  "hideCodeExecute": true,
                  "show": {
                    "llmStructuredOutput[$index].type": "jsonArray"
                  }
                },
                {
                  "label": "Description",
                  "name": "description",
                  "type": "string",
                  "placeholder": "Description of the key"
                }
              ],
              "id": "llmAgentflow_2-input-llmStructuredOutput-array",
              "display": true
            },
            {
              "label": "Update Flow State",
              "name": "llmUpdateState",
              "description": "Update runtime state during the execution of the workflow",
              "type": "array",
              "optional": true,
              "acceptVariable": true,
              "array": [
                {
                  "label": "Key",
                  "name": "key",
                  "type": "asyncOptions",
                  "loadMethod": "listRuntimeStateKeys",
                  "freeSolo": true
                },
                {
                  "label": "Value",
                  "name": "value",
                  "type": "string",
                  "acceptVariable": true,
                  "acceptNodeOutputAsVariable": true
                }
              ],
              "id": "llmAgentflow_2-input-llmUpdateState-array",
              "display": true
            }
          ],
          "inputAnchors": [],
          "inputs": {
            "llmModel": "chatGoogleGenerativeAI",
            "llmMessages": [
              {
                "role": "system",
                "content": "<p>As a Quality Assurance Engineer, you are an integral part of our development team, ensuring that our software products are of the highest quality. Your meticulous attention to detail and expertise in testing methodologies are crucial in identifying defects and ensuring that our code meets the highest standards.</p><p>Your goal is to ensure the delivery of high-quality software through thorough code review and testing.</p><p>Review the codebase for the new feature designed and implemented by the Senior Software Engineer. Provide constructive feedback, guiding contributors towards best practices and fostering a culture of continuous improvement. Your approach ensures the delivery of high-quality software that is robust, scalable, and aligned with strategic goals.</p>"
              }
            ],
            "llmEnableMemory": true,
            "llmMemoryType": "allMessages",
            "llmUserMessage": "<p>Supervisor Instruction:</p><p><span class=\"variable\" data-type=\"mention\" data-id=\"$flow.state.instructions\" data-label=\"$flow.state.instructions\">{{ $flow.state.instructions }}</span> </p>",
            "llmReturnResponseAs": "userMessage",
            "llmStructuredOutput": "",
            "llmUpdateState": "",
            "llmModelConfig": {
              "credential": "",
              "modelName": "gemini-2.5-flash-preview-05-20",
              "customModelName": "",
              "temperature": 0.9,
              "streaming": true,
              "maxOutputTokens": "",
              "topP": "",
              "topK": "",
              "safetySettings": "",
              "baseUrl": "",
              "allowImageUploads": "",
              "llmModel": "chatGoogleGenerativeAI"
            }
          },
          "outputAnchors": [
            {
              "id": "llmAgentflow_2-output-llmAgentflow",
              "label": "LLM",
              "name": "llmAgentflow"
            }
          ],
          "outputs": {},
          "selected": false
        },
        "type": "agentFlow",
        "width": 283,
        "height": 72,
        "selected": false,
        "positionAbsolute": {
          "x": 275.82767406990337,
          "y": 82.77476864566805
        },
        "dragging": false
      },
      {
        "id": "loopAgentflow_1",
        "position": {
          "x": 605.9007401528584,
          "y": 86.04727674557375
        },
        "data": {
          "id": "loopAgentflow_1",
          "label": "Loop to Supervisor",
          "version": 1,
          "name": "loopAgentflow",
          "type": "Loop",
          "color": "#FFA07A",
          "hideOutput": true,
          "baseClasses": [
            "Loop"
          ],
          "category": "Agent Flows",
          "description": "Loop back to a previous node",
          "inputParams": [
            {
              "label": "Loop Back To",
              "name": "loopBackToNode",
              "type": "asyncOptions",
              "loadMethod": "listPreviousNodes",
              "freeSolo": true,
              "id": "loopAgentflow_1-input-loopBackToNode-asyncOptions",
              "display": true
            },
            {
              "label": "Max Loop Count",
              "name": "maxLoopCount",
              "type": "number",
              "default": 5,
              "id": "loopAgentflow_1-input-maxLoopCount-number",
              "display": true
            }
          ],
          "inputAnchors": [],
          "inputs": {
            "loopBackToNode": "llmAgentflow_0-Supervisor",
            "maxLoopCount": "3"
          },
          "outputAnchors": [],
          "outputs": {},
          "selected": false
        },
        "type": "agentFlow",
        "width": 195,
        "height": 66,
        "selected": false,
        "dragging": false,
        "positionAbsolute": {
          "x": 605.9007401528584,
          "y": 86.04727674557375
        }
      },
      {
        "id": "llmAgentflow_3",
        "position": {
          "x": 281.61304397426727,
          "y": 197.2742730982714
        },
        "data": {
          "id": "llmAgentflow_3",
          "label": "Generating Json",
          "version": 1,
          "name": "llmAgentflow",
          "type": "LLM",
          "color": "#64B5F6",
          "baseClasses": [
            "LLM"
          ],
          "category": "Agent Flows",
          "description": "Large language models to analyze user-provided inputs and generate responses",
          "inputParams": [
            {
              "label": "Model",
              "name": "llmModel",
              "type": "asyncOptions",
              "loadMethod": "listModels",
              "loadConfig": true,
              "id": "llmAgentflow_3-input-llmModel-asyncOptions",
              "display": true
            },
            {
              "label": "Messages",
              "name": "llmMessages",
              "type": "array",
              "optional": true,
              "acceptVariable": true,
              "array": [
                {
                  "label": "Role",
                  "name": "role",
                  "type": "options",
                  "options": [
                    {
                      "label": "System",
                      "name": "system"
                    },
                    {
                      "label": "Assistant",
                      "name": "assistant"
                    },
                    {
                      "label": "Developer",
                      "name": "developer"
                    },
                    {
                      "label": "User",
                      "name": "user"
                    }
                  ]
                },
                {
                  "label": "Content",
                  "name": "content",
                  "type": "string",
                  "acceptVariable": true,
                  "generateInstruction": true,
                  "rows": 4
                }
              ],
              "id": "llmAgentflow_3-input-llmMessages-array",
              "display": true
            },
            {
              "label": "Enable Memory",
              "name": "llmEnableMemory",
              "type": "boolean",
              "description": "Enable memory for the conversation thread",
              "default": true,
              "optional": true,
              "id": "llmAgentflow_3-input-llmEnableMemory-boolean",
              "display": true
            },
            {
              "label": "Memory Type",
              "name": "llmMemoryType",
              "type": "options",
              "options": [
                {
                  "label": "All Messages",
                  "name": "allMessages",
                  "description": "Retrieve all messages from the conversation"
                },
                {
                  "label": "Window Size",
                  "name": "windowSize",
                  "description": "Uses a fixed window size to surface the last N messages"
                },
                {
                  "label": "Conversation Summary",
                  "name": "conversationSummary",
                  "description": "Summarizes the whole conversation"
                },
                {
                  "label": "Conversation Summary Buffer",
                  "name": "conversationSummaryBuffer",
                  "description": "Summarize conversations once token limit is reached. Default to 2000"
                }
              ],
              "optional": true,
              "default": "allMessages",
              "show": {
                "llmEnableMemory": true
              },
              "id": "llmAgentflow_3-input-llmMemoryType-options",
              "display": true
            },
            {
              "label": "Window Size",
              "name": "llmMemoryWindowSize",
              "type": "number",
              "default": "20",
              "description": "Uses a fixed window size to surface the last N messages",
              "show": {
                "llmMemoryType": "windowSize"
              },
              "id": "llmAgentflow_3-input-llmMemoryWindowSize-number",
              "display": false
            },
            {
              "label": "Max Token Limit",
              "name": "llmMemoryMaxTokenLimit",
              "type": "number",
              "default": "2000",
              "description": "Summarize conversations once token limit is reached. Default to 2000",
              "show": {
                "llmMemoryType": "conversationSummaryBuffer"
              },
              "id": "llmAgentflow_3-input-llmMemoryMaxTokenLimit-number",
              "display": false
            },
            {
              "label": "Input Message",
              "name": "llmUserMessage",
              "type": "string",
              "description": "Add an input message as user message at the end of the conversation",
              "rows": 4,
              "optional": true,
              "acceptVariable": true,
              "show": {
                "llmEnableMemory": true
              },
              "id": "llmAgentflow_3-input-llmUserMessage-string",
              "display": true
            },
            {
              "label": "Return Response As",
              "name": "llmReturnResponseAs",
              "type": "options",
              "options": [
                {
                  "label": "User Message",
                  "name": "userMessage"
                },
                {
                  "label": "Assistant Message",
                  "name": "assistantMessage"
                }
              ],
              "default": "userMessage",
              "id": "llmAgentflow_3-input-llmReturnResponseAs-options",
              "display": true
            },
            {
              "label": "JSON Structured Output",
              "name": "llmStructuredOutput",
              "description": "Instruct the LLM to give output in a JSON structured schema",
              "type": "array",
              "optional": true,
              "acceptVariable": true,
              "array": [
                {
                  "label": "Key",
                  "name": "key",
                  "type": "string"
                },
                {
                  "label": "Type",
                  "name": "type",
                  "type": "options",
                  "options": [
                    {
                      "label": "String",
                      "name": "string"
                    },
                    {
                      "label": "String Array",
                      "name": "stringArray"
                    },
                    {
                      "label": "Number",
                      "name": "number"
                    },
                    {
                      "label": "Boolean",
                      "name": "boolean"
                    },
                    {
                      "label": "Enum",
                      "name": "enum"
                    },
                    {
                      "label": "JSON Array",
                      "name": "jsonArray"
                    }
                  ]
                },
                {
                  "label": "Enum Values",
                  "name": "enumValues",
                  "type": "string",
                  "placeholder": "value1, value2, value3",
                  "description": "Enum values. Separated by comma",
                  "optional": true,
                  "show": {
                    "llmStructuredOutput[$index].type": "enum"
                  }
                },
                {
                  "label": "JSON Schema",
                  "name": "jsonSchema",
                  "type": "code",
                  "placeholder": "{\n    \"answer\": {\n        \"type\": \"string\",\n        \"description\": \"Value of the answer\"\n    },\n    \"reason\": {\n        \"type\": \"string\",\n        \"description\": \"Reason for the answer\"\n    },\n    \"optional\": {\n        \"type\": \"boolean\"\n    },\n    \"count\": {\n        \"type\": \"number\"\n    },\n    \"children\": {\n        \"type\": \"array\",\n        \"items\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"value\": {\n                    \"type\": \"string\",\n                    \"description\": \"Value of the children's answer\"\n                }\n            }\n        }\n    }\n}",
                  "description": "JSON schema for the structured output",
                  "optional": true,
                  "hideCodeExecute": true,
                  "show": {
                    "llmStructuredOutput[$index].type": "jsonArray"
                  }
                },
                {
                  "label": "Description",
                  "name": "description",
                  "type": "string",
                  "placeholder": "Description of the key"
                }
              ],
              "id": "llmAgentflow_3-input-llmStructuredOutput-array",
              "display": true
            },
            {
              "label": "Update Flow State",
              "name": "llmUpdateState",
              "description": "Update runtime state during the execution of the workflow",
              "type": "array",
              "optional": true,
              "acceptVariable": true,
              "array": [
                {
                  "label": "Key",
                  "name": "key",
                  "type": "asyncOptions",
                  "loadMethod": "listRuntimeStateKeys",
                  "freeSolo": true
                },
                {
                  "label": "Value",
                  "name": "value",
                  "type": "string",
                  "acceptVariable": true,
                  "acceptNodeOutputAsVariable": true
                }
              ],
              "id": "llmAgentflow_3-input-llmUpdateState-array",
              "display": true
            }
          ],
          "inputAnchors": [],
          "inputs": {
            "llmModel": "chatGoogleGenerativeAI",
            "llmMessages": [],
            "llmEnableMemory": true,
            "llmMemoryType": "allMessages",
            "llmUserMessage": "<p>You must output a single, valid JSON object that strictly adheres to the following format. Do NOT include any conversational text or explanations.</p><p>The JSON format must be: { \"files\": [ { \"path\": \"path/to/file.py\", \"content\": \"file content\" } ]</p>",
            "llmReturnResponseAs": "userMessage",
            "llmStructuredOutput": "",
            "llmUpdateState": [
              {
                "key": "input",
                "value": "<p><span class=\"variable\" data-type=\"mention\" data-id=\"output\" data-label=\"output\">{{ output }}</span> </p>"
              }
            ],
            "llmModelConfig": {
              "credential": "",
              "modelName": "gemini-2.5-flash-preview-05-20",
              "customModelName": "",
              "temperature": 0.9,
              "streaming": true,
              "maxOutputTokens": "",
              "topP": "",
              "topK": "",
              "safetySettings": "",
              "baseUrl": "",
              "allowImageUploads": "",
              "llmModel": "chatGoogleGenerativeAI"
            },
            "undefined": ""
          },
          "outputAnchors": [
            {
              "id": "llmAgentflow_3-output-llmAgentflow",
              "label": "LLM",
              "name": "llmAgentflow"
            }
          ],
          "outputs": {},
          "selected": false
        },
        "type": "agentFlow",
        "width": 283,
        "height": 72,
        "selected": false,
        "positionAbsolute": {
          "x": 281.61304397426727,
          "y": 197.2742730982714
        },
        "dragging": false
      },
      {
        "id": "customFunctionAgentflow_0",
        "position": {
          "x": 609.7668540733292,
          "y": 200.66712219987159
        },
        "data": {
          "id": "customFunctionAgentflow_0",
          "label": "Tuning Json",
          "version": 1,
          "name": "customFunctionAgentflow",
          "type": "CustomFunction",
          "color": "#E4B7FF",
          "baseClasses": [
            "CustomFunction"
          ],
          "category": "Agent Flows",
          "description": "Execute custom function",
          "inputParams": [
            {
              "label": "Input Variables",
              "name": "customFunctionInputVariables",
              "description": "Input variables can be used in the function with prefix $. For example: $foo",
              "type": "array",
              "optional": true,
              "acceptVariable": true,
              "array": [
                {
                  "label": "Variable Name",
                  "name": "variableName",
                  "type": "string"
                },
                {
                  "label": "Variable Value",
                  "name": "variableValue",
                  "type": "string",
                  "acceptVariable": true
                }
              ],
              "id": "customFunctionAgentflow_0-input-customFunctionInputVariables-array",
              "display": true
            },
            {
              "label": "Javascript Function",
              "name": "customFunctionJavascriptFunction",
              "type": "code",
              "codeExample": "/*\n* You can use any libraries imported in Flowise\n* You can use properties specified in Input Variables with the prefix $. For example: $foo\n* You can get default flow config: $flow.sessionId, $flow.chatId, $flow.chatflowId, $flow.input, $flow.state\n* You can get global variables: $vars.<variable-name>\n* Must return a string value at the end of function\n*/\n\nconst fetch = require('node-fetch');\nconst url = 'https://api.open-meteo.com/v1/forecast?latitude=52.52&longitude=13.41&current_weather=true';\nconst options = {\n    method: 'GET',\n    headers: {\n        'Content-Type': 'application/json'\n    }\n};\ntry {\n    const response = await fetch(url, options);\n    const text = await response.text();\n    return text;\n} catch (error) {\n    console.error(error);\n    return '';\n}",
              "description": "The function to execute. Must return a string or an object that can be converted to a string.",
              "id": "customFunctionAgentflow_0-input-customFunctionJavascriptFunction-code",
              "display": true
            },
            {
              "label": "Update Flow State",
              "name": "customFunctionUpdateState",
              "description": "Update runtime state during the execution of the workflow",
              "type": "array",
              "optional": true,
              "acceptVariable": true,
              "array": [
                {
                  "label": "Key",
                  "name": "key",
                  "type": "asyncOptions",
                  "loadMethod": "listRuntimeStateKeys",
                  "freeSolo": true
                },
                {
                  "label": "Value",
                  "name": "value",
                  "type": "string",
                  "acceptVariable": true,
                  "acceptNodeOutputAsVariable": true
                }
              ],
              "id": "customFunctionAgentflow_0-input-customFunctionUpdateState-array",
              "display": true
            }
          ],
          "inputAnchors": [],
          "inputs": {
            "customFunctionInputVariables": [
              {
                "variableName": "input",
                "variableValue": "<p><span class=\"variable\" data-type=\"mention\" data-id=\"$flow.state.input\" data-label=\"$flow.state.input\">{{ $flow.state.input }}</span> </p>"
              }
            ],
            "customFunctionJavascriptFunction": "const llmOutput = $input;\nlet jsonResult = null;\n\n// First, try to parse the input directly. This handles clean JSON.\ntry {\n  jsonResult = JSON.parse(llmOutput);\n} catch (directParseError) {\n  // If direct parsing fails, use the regex to handle Markdown fences.\n  const regex = /```(?:json)?\\s*({[\\s\\S]*?})\\s*```/;\n  const match = llmOutput.match(regex);\n  if (match && match[1]) {\n    try {\n      jsonResult = JSON.parse(match[1]);\n    } catch (regexParseError) {\n      // Log an error if the extracted JSON is also invalid.\n      console.error(\"Error parsing extracted JSON string:\", regexParseError);\n    }\n  }\n}\n\n// Ensure jsonResult is a valid object with a 'files' array, otherwise use the fallback.\nif (!jsonResult || typeof jsonResult !== 'object' || !Array.isArray(jsonResult.files)) {\n  jsonResult = { files: [] };\n}\n\n// Return the final result as a string.\nreturn JSON.stringify(jsonResult);",
            "customFunctionUpdateState": ""
          },
          "outputAnchors": [
            {
              "id": "customFunctionAgentflow_0-output-customFunctionAgentflow",
              "label": "Custom Function",
              "name": "customFunctionAgentflow"
            }
          ],
          "outputs": {},
          "selected": false
        },
        "type": "agentFlow",
        "width": 151,
        "height": 66,
        "selected": false,
        "positionAbsolute": {
          "x": 609.7668540733292,
          "y": 200.66712219987159
        },
        "dragging": false
      },
      {
        "id": "httpAgentflow_0",
        "position": {
          "x": 813.5676754036696,
          "y": 200.47461844812068
        },
        "data": {
          "id": "httpAgentflow_0",
          "label": "HTTP",
          "version": 1.1,
          "name": "httpAgentflow",
          "type": "HTTP",
          "color": "#FF7F7F",
          "baseClasses": [
            "HTTP"
          ],
          "category": "Agent Flows",
          "description": "Send a HTTP request",
          "inputParams": [
            {
              "label": "HTTP Credential",
              "name": "credential",
              "type": "credential",
              "credentialNames": [
                "httpBasicAuth",
                "httpBearerToken",
                "httpApiKey"
              ],
              "optional": true,
              "id": "httpAgentflow_0-input-credential-credential",
              "display": true
            },
            {
              "label": "Method",
              "name": "method",
              "type": "options",
              "options": [
                {
                  "label": "GET",
                  "name": "GET"
                },
                {
                  "label": "POST",
                  "name": "POST"
                },
                {
                  "label": "PUT",
                  "name": "PUT"
                },
                {
                  "label": "DELETE",
                  "name": "DELETE"
                },
                {
                  "label": "PATCH",
                  "name": "PATCH"
                }
              ],
              "default": "GET",
              "id": "httpAgentflow_0-input-method-options",
              "display": true
            },
            {
              "label": "URL",
              "name": "url",
              "type": "string",
              "id": "httpAgentflow_0-input-url-string",
              "display": true
            },
            {
              "label": "Headers",
              "name": "headers",
              "type": "array",
              "acceptVariable": true,
              "array": [
                {
                  "label": "Key",
                  "name": "key",
                  "type": "string",
                  "default": ""
                },
                {
                  "label": "Value",
                  "name": "value",
                  "type": "string",
                  "default": "",
                  "acceptVariable": true
                }
              ],
              "optional": true,
              "id": "httpAgentflow_0-input-headers-array",
              "display": true
            },
            {
              "label": "Query Params",
              "name": "queryParams",
              "type": "array",
              "acceptVariable": true,
              "array": [
                {
                  "label": "Key",
                  "name": "key",
                  "type": "string",
                  "default": ""
                },
                {
                  "label": "Value",
                  "name": "value",
                  "type": "string",
                  "default": "",
                  "acceptVariable": true
                }
              ],
              "optional": true,
              "id": "httpAgentflow_0-input-queryParams-array",
              "display": true
            },
            {
              "label": "Body Type",
              "name": "bodyType",
              "type": "options",
              "options": [
                {
                  "label": "JSON",
                  "name": "json"
                },
                {
                  "label": "Raw",
                  "name": "raw"
                },
                {
                  "label": "Form Data",
                  "name": "formData"
                },
                {
                  "label": "x-www-form-urlencoded",
                  "name": "xWwwFormUrlencoded"
                }
              ],
              "optional": true,
              "id": "httpAgentflow_0-input-bodyType-options",
              "display": true
            },
            {
              "label": "Body",
              "name": "body",
              "type": "string",
              "acceptVariable": true,
              "rows": 4,
              "show": {
                "bodyType": [
                  "raw",
                  "json"
                ]
              },
              "optional": true,
              "id": "httpAgentflow_0-input-body-string",
              "display": true
            },
            {
              "label": "Body",
              "name": "body",
              "type": "array",
              "acceptVariable": true,
              "show": {
                "bodyType": [
                  "xWwwFormUrlencoded",
                  "formData"
                ]
              },
              "array": [
                {
                  "label": "Key",
                  "name": "key",
                  "type": "string",
                  "default": ""
                },
                {
                  "label": "Value",
                  "name": "value",
                  "type": "string",
                  "default": "",
                  "acceptVariable": true
                }
              ],
              "optional": true,
              "id": "httpAgentflow_0-input-body-array",
              "display": false
            },
            {
              "label": "Response Type",
              "name": "responseType",
              "type": "options",
              "options": [
                {
                  "label": "JSON",
                  "name": "json"
                },
                {
                  "label": "Text",
                  "name": "text"
                },
                {
                  "label": "Array Buffer",
                  "name": "arraybuffer"
                },
                {
                  "label": "Raw (Base64)",
                  "name": "base64"
                }
              ],
              "optional": true,
              "id": "httpAgentflow_0-input-responseType-options",
              "display": true
            }
          ],
          "inputAnchors": [],
          "inputs": {
            "method": "POST",
            "url": "http://localhost:8000/generate-zip",
            "headers": [
              {
                "key": "Content-Type",
                "value": "<p>application/json</p>"
              }
            ],
            "queryParams": "",
            "bodyType": "json",
            "responseType": "",
            "body": "<p><span class=\"variable\" data-type=\"mention\" data-id=\"customFunctionAgentflow_0\" data-label=\"customFunctionAgentflow_0\">{{ customFunctionAgentflow_0 }}</span> </p>"
          },
          "outputAnchors": [
            {
              "id": "httpAgentflow_0-output-httpAgentflow",
              "label": "HTTP",
              "name": "httpAgentflow"
            }
          ],
          "outputs": {},
          "selected": false
        },
        "type": "agentFlow",
        "width": 108,
        "height": 66,
        "selected": false,
        "positionAbsolute": {
          "x": 813.5676754036696,
          "y": 200.47461844812068
        },
        "dragging": false
      },
      {
        "id": "llmAgentflow_4",
        "position": {
          "x": 964.6485435441193,
          "y": 198.75676159123466
        },
        "data": {
          "id": "llmAgentflow_4",
          "label": "Instruction and Zip",
          "version": 1,
          "name": "llmAgentflow",
          "type": "LLM",
          "color": "#64B5F6",
          "baseClasses": [
            "LLM"
          ],
          "category": "Agent Flows",
          "description": "Large language models to analyze user-provided inputs and generate responses",
          "inputParams": [
            {
              "label": "Model",
              "name": "llmModel",
              "type": "asyncOptions",
              "loadMethod": "listModels",
              "loadConfig": true,
              "id": "llmAgentflow_4-input-llmModel-asyncOptions",
              "display": true
            },
            {
              "label": "Messages",
              "name": "llmMessages",
              "type": "array",
              "optional": true,
              "acceptVariable": true,
              "array": [
                {
                  "label": "Role",
                  "name": "role",
                  "type": "options",
                  "options": [
                    {
                      "label": "System",
                      "name": "system"
                    },
                    {
                      "label": "Assistant",
                      "name": "assistant"
                    },
                    {
                      "label": "Developer",
                      "name": "developer"
                    },
                    {
                      "label": "User",
                      "name": "user"
                    }
                  ]
                },
                {
                  "label": "Content",
                  "name": "content",
                  "type": "string",
                  "acceptVariable": true,
                  "generateInstruction": true,
                  "rows": 4
                }
              ],
              "id": "llmAgentflow_4-input-llmMessages-array",
              "display": true
            },
            {
              "label": "Enable Memory",
              "name": "llmEnableMemory",
              "type": "boolean",
              "description": "Enable memory for the conversation thread",
              "default": true,
              "optional": true,
              "id": "llmAgentflow_4-input-llmEnableMemory-boolean",
              "display": true
            },
            {
              "label": "Memory Type",
              "name": "llmMemoryType",
              "type": "options",
              "options": [
                {
                  "label": "All Messages",
                  "name": "allMessages",
                  "description": "Retrieve all messages from the conversation"
                },
                {
                  "label": "Window Size",
                  "name": "windowSize",
                  "description": "Uses a fixed window size to surface the last N messages"
                },
                {
                  "label": "Conversation Summary",
                  "name": "conversationSummary",
                  "description": "Summarizes the whole conversation"
                },
                {
                  "label": "Conversation Summary Buffer",
                  "name": "conversationSummaryBuffer",
                  "description": "Summarize conversations once token limit is reached. Default to 2000"
                }
              ],
              "optional": true,
              "default": "allMessages",
              "show": {
                "llmEnableMemory": true
              },
              "id": "llmAgentflow_4-input-llmMemoryType-options",
              "display": true
            },
            {
              "label": "Window Size",
              "name": "llmMemoryWindowSize",
              "type": "number",
              "default": "20",
              "description": "Uses a fixed window size to surface the last N messages",
              "show": {
                "llmMemoryType": "windowSize"
              },
              "id": "llmAgentflow_4-input-llmMemoryWindowSize-number",
              "display": false
            },
            {
              "label": "Max Token Limit",
              "name": "llmMemoryMaxTokenLimit",
              "type": "number",
              "default": "2000",
              "description": "Summarize conversations once token limit is reached. Default to 2000",
              "show": {
                "llmMemoryType": "conversationSummaryBuffer"
              },
              "id": "llmAgentflow_4-input-llmMemoryMaxTokenLimit-number",
              "display": false
            },
            {
              "label": "Input Message",
              "name": "llmUserMessage",
              "type": "string",
              "description": "Add an input message as user message at the end of the conversation",
              "rows": 4,
              "optional": true,
              "acceptVariable": true,
              "show": {
                "llmEnableMemory": true
              },
              "id": "llmAgentflow_4-input-llmUserMessage-string",
              "display": true
            },
            {
              "label": "Return Response As",
              "name": "llmReturnResponseAs",
              "type": "options",
              "options": [
                {
                  "label": "User Message",
                  "name": "userMessage"
                },
                {
                  "label": "Assistant Message",
                  "name": "assistantMessage"
                }
              ],
              "default": "userMessage",
              "id": "llmAgentflow_4-input-llmReturnResponseAs-options",
              "display": true
            },
            {
              "label": "JSON Structured Output",
              "name": "llmStructuredOutput",
              "description": "Instruct the LLM to give output in a JSON structured schema",
              "type": "array",
              "optional": true,
              "acceptVariable": true,
              "array": [
                {
                  "label": "Key",
                  "name": "key",
                  "type": "string"
                },
                {
                  "label": "Type",
                  "name": "type",
                  "type": "options",
                  "options": [
                    {
                      "label": "String",
                      "name": "string"
                    },
                    {
                      "label": "String Array",
                      "name": "stringArray"
                    },
                    {
                      "label": "Number",
                      "name": "number"
                    },
                    {
                      "label": "Boolean",
                      "name": "boolean"
                    },
                    {
                      "label": "Enum",
                      "name": "enum"
                    },
                    {
                      "label": "JSON Array",
                      "name": "jsonArray"
                    }
                  ]
                },
                {
                  "label": "Enum Values",
                  "name": "enumValues",
                  "type": "string",
                  "placeholder": "value1, value2, value3",
                  "description": "Enum values. Separated by comma",
                  "optional": true,
                  "show": {
                    "llmStructuredOutput[$index].type": "enum"
                  }
                },
                {
                  "label": "JSON Schema",
                  "name": "jsonSchema",
                  "type": "code",
                  "placeholder": "{\n    \"answer\": {\n        \"type\": \"string\",\n        \"description\": \"Value of the answer\"\n    },\n    \"reason\": {\n        \"type\": \"string\",\n        \"description\": \"Reason for the answer\"\n    },\n    \"optional\": {\n        \"type\": \"boolean\"\n    },\n    \"count\": {\n        \"type\": \"number\"\n    },\n    \"children\": {\n        \"type\": \"array\",\n        \"items\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"value\": {\n                    \"type\": \"string\",\n                    \"description\": \"Value of the children's answer\"\n                }\n            }\n        }\n    }\n}",
                  "description": "JSON schema for the structured output",
                  "optional": true,
                  "hideCodeExecute": true,
                  "show": {
                    "llmStructuredOutput[$index].type": "jsonArray"
                  }
                },
                {
                  "label": "Description",
                  "name": "description",
                  "type": "string",
                  "placeholder": "Description of the key"
                }
              ],
              "id": "llmAgentflow_4-input-llmStructuredOutput-array",
              "display": true
            },
            {
              "label": "Update Flow State",
              "name": "llmUpdateState",
              "description": "Update runtime state during the execution of the workflow",
              "type": "array",
              "optional": true,
              "acceptVariable": true,
              "array": [
                {
                  "label": "Key",
                  "name": "key",
                  "type": "asyncOptions",
                  "loadMethod": "listRuntimeStateKeys",
                  "freeSolo": true
                },
                {
                  "label": "Value",
                  "name": "value",
                  "type": "string",
                  "acceptVariable": true,
                  "acceptNodeOutputAsVariable": true
                }
              ],
              "id": "llmAgentflow_4-input-llmUpdateState-array",
              "display": true
            }
          ],
          "inputAnchors": [],
          "inputs": {
            "llmModel": "chatGoogleGenerativeAI",
            "llmMessages": [
              {
                "role": "system",
                "content": "<p>You are a Senior Software Engineer. Your task is to review the generated application and provide a professional summary. Follow the structure and rules below:</p><p>1. Folder Structure</p><p>- Present a clear hierarchical view of all folders and files.</p><p>- Use a tree-like structure with proper indentation.</p><p>- Highlight key files such as entry points and configuration files.</p><p>- Add a brief explanation of the purpose of any important folders or files.</p><p>2. Folder Structure Program</p><p>- Generate a script (in Node.js or Python) that programmatically creates the same folder structure with empty files.</p><p>- The script must be clean, executable, and include comments explaining each part.</p><p>3. Setup and Run Instructions</p><p>- List all prerequisites (Node.js, Python, or other dependencies).</p><p>- Include steps to install dependencies.</p><p>- Provide commands to:</p><p>  - Run the application in development mode.</p><p>  - Run the application in production mode.</p><p>  - Build or package the application (if applicable).</p><p>  - Run tests (if available).</p><p>4. File Object for Download (NOT markdown, single line JSON)</p><p>- Instead of showing a link, return a file object as a single line string.</p><p>- Use the HTTP node response value data.download_url.</p><p>- Return:</p><p>  http://10.10.20.156:8000{{data.download_url}}</p><p>- DO NOT:</p><p>  - Add quotes</p><p>  - Add markdown</p><p>  - Add line breaks</p><p>  - Return as JSON unless download_url is missing</p><p>- If data.download_url is missing, return exactly:</p><p>  {\"url\":\"\"}</p><p>- This must render as a download button in Flowise.</p><p>5. Additional Notes (if applicable)</p><p>- List required environment variables with short explanations.</p><p>- Provide troubleshooting tips for common setup issues.</p><p>- Suggest best practices for maintaining or extending the project.</p><p>Rules:</p><p>- Follow the format strictly and in order.</p><p>- Keep explanations concise and beginner-friendly.</p><p>- Ensure the folder-creating script is valid and well-commented.</p><p>- Only return the download URL line exactly as required to render the download icon in Flowise.</p><p>- NEVER include the full HTTP response.</p><p>- NEVER return the URL in a JSON object unless data.download_url is missing.</p><p></p>"
              }
            ],
            "llmEnableMemory": true,
            "llmMemoryType": "allMessages",
            "llmUserMessage": "<p><span class=\"variable\" data-type=\"mention\" data-id=\"httpAgentflow_0\" data-label=\"httpAgentflow_0\">{{ httpAgentflow_0 }}</span> <br><span class=\"variable\" data-type=\"mention\" data-id=\"customFunctionAgentflow_0\" data-label=\"customFunctionAgentflow_0\">{{ customFunctionAgentflow_0 }}</span> </p>",
            "llmReturnResponseAs": "userMessage",
            "llmStructuredOutput": "",
            "llmUpdateState": "",
            "llmModelConfig": {
              "cache": "",
              "modelName": "gemini-2.5-flash-preview-05-20",
              "customModelName": "",
              "temperature": 0.9,
              "streaming": true,
              "maxOutputTokens": "",
              "topP": "",
              "topK": "",
              "safetySettings": "",
              "baseUrl": "",
              "allowImageUploads": "",
              "llmModel": "chatGoogleGenerativeAI"
            }
          },
          "outputAnchors": [
            {
              "id": "llmAgentflow_4-output-llmAgentflow",
              "label": "LLM",
              "name": "llmAgentflow"
            }
          ],
          "outputs": {},
          "selected": false
        },
        "type": "agentFlow",
        "width": 283,
        "height": 72,
        "selected": false,
        "positionAbsolute": {
          "x": 964.6485435441193,
          "y": 198.75676159123466
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "startAgentflow_0",
        "sourceHandle": "startAgentflow_0-output-startAgentflow",
        "target": "llmAgentflow_0",
        "targetHandle": "llmAgentflow_0",
        "data": {
          "sourceColor": "#7EE787",
          "targetColor": "#64B5F6",
          "isHumanInput": false
        },
        "type": "agentFlow",
        "id": "startAgentflow_0-startAgentflow_0-output-startAgentflow-llmAgentflow_0-llmAgentflow_0"
      },
      {
        "source": "llmAgentflow_0",
        "sourceHandle": "llmAgentflow_0-output-llmAgentflow",
        "target": "conditionAgentflow_0",
        "targetHandle": "conditionAgentflow_0",
        "data": {
          "sourceColor": "#64B5F6",
          "targetColor": "#FFB938",
          "isHumanInput": false
        },
        "type": "agentFlow",
        "id": "llmAgentflow_0-llmAgentflow_0-output-llmAgentflow-conditionAgentflow_0-conditionAgentflow_0"
      },
      {
        "source": "conditionAgentflow_0",
        "sourceHandle": "conditionAgentflow_0-output-0",
        "target": "llmAgentflow_1",
        "targetHandle": "llmAgentflow_1",
        "data": {
          "sourceColor": "#FFB938",
          "targetColor": "#64B5F6",
          "edgeLabel": "0",
          "isHumanInput": false
        },
        "type": "agentFlow",
        "id": "conditionAgentflow_0-conditionAgentflow_0-output-0-llmAgentflow_1-llmAgentflow_1"
      },
      {
        "source": "llmAgentflow_1",
        "sourceHandle": "llmAgentflow_1-output-llmAgentflow",
        "target": "loopAgentflow_0",
        "targetHandle": "loopAgentflow_0",
        "data": {
          "sourceColor": "#64B5F6",
          "targetColor": "#FFA07A",
          "isHumanInput": false
        },
        "type": "agentFlow",
        "id": "llmAgentflow_1-llmAgentflow_1-output-llmAgentflow-loopAgentflow_0-loopAgentflow_0"
      },
      {
        "source": "conditionAgentflow_0",
        "sourceHandle": "conditionAgentflow_0-output-1",
        "target": "llmAgentflow_2",
        "targetHandle": "llmAgentflow_2",
        "data": {
          "sourceColor": "#FFB938",
          "targetColor": "#64B5F6",
          "edgeLabel": "1",
          "isHumanInput": false
        },
        "type": "agentFlow",
        "id": "conditionAgentflow_0-conditionAgentflow_0-output-1-llmAgentflow_2-llmAgentflow_2"
      },
      {
        "source": "llmAgentflow_2",
        "sourceHandle": "llmAgentflow_2-output-llmAgentflow",
        "target": "loopAgentflow_1",
        "targetHandle": "loopAgentflow_1",
        "data": {
          "sourceColor": "#64B5F6",
          "targetColor": "#FFA07A",
          "isHumanInput": false
        },
        "type": "agentFlow",
        "id": "llmAgentflow_2-llmAgentflow_2-output-llmAgentflow-loopAgentflow_1-loopAgentflow_1"
      },
      {
        "source": "llmAgentflow_3",
        "sourceHandle": "llmAgentflow_3-output-llmAgentflow",
        "target": "customFunctionAgentflow_0",
        "targetHandle": "customFunctionAgentflow_0",
        "data": {
          "sourceColor": "#64B5F6",
          "targetColor": "#E4B7FF",
          "isHumanInput": false
        },
        "type": "agentFlow",
        "id": "llmAgentflow_3-llmAgentflow_3-output-llmAgentflow-customFunctionAgentflow_0-customFunctionAgentflow_0"
      },
      {
        "source": "customFunctionAgentflow_0",
        "sourceHandle": "customFunctionAgentflow_0-output-customFunctionAgentflow",
        "target": "httpAgentflow_0",
        "targetHandle": "httpAgentflow_0",
        "data": {
          "sourceColor": "#E4B7FF",
          "targetColor": "#FF7F7F",
          "isHumanInput": false
        },
        "type": "agentFlow",
        "id": "customFunctionAgentflow_0-customFunctionAgentflow_0-output-customFunctionAgentflow-httpAgentflow_0-httpAgentflow_0"
      },
      {
        "source": "conditionAgentflow_0",
        "sourceHandle": "conditionAgentflow_0-output-2",
        "target": "llmAgentflow_3",
        "targetHandle": "llmAgentflow_3",
        "data": {
          "sourceColor": "#FFB938",
          "targetColor": "#64B5F6",
          "edgeLabel": "2",
          "isHumanInput": false
        },
        "type": "agentFlow",
        "id": "conditionAgentflow_0-conditionAgentflow_0-output-2-llmAgentflow_3-llmAgentflow_3"
      },
      {
        "source": "httpAgentflow_0",
        "sourceHandle": "httpAgentflow_0-output-httpAgentflow",
        "target": "llmAgentflow_4",
        "targetHandle": "llmAgentflow_4",
        "data": {
          "sourceColor": "#FF7F7F",
          "targetColor": "#64B5F6",
          "isHumanInput": false
        },
        "type": "agentFlow",
        "id": "httpAgentflow_0-httpAgentflow_0-output-httpAgentflow-llmAgentflow_4-llmAgentflow_4"
      }
    ]
  }